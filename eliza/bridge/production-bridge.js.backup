import express from 'express';
import cors from 'cors';
import compression from 'compression';
import helmet from 'helmet';
import rateLimit from 'express-rate-limit';
import { createServer } from 'http';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import { createClient } from '@supabase/supabase-js';
import OpenAI from 'openai';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Production-optimized ElizaOS Bridge
class ProductionElizaBridge {
  constructor() {
    this.app = express();
    this.server = createServer(this.app);
    this.characters = new Map();
    this.responseCache = new Map();
    
    // Initialize Supabase client
    const supabaseUrl = process.env.SUPABASE_URL;
    const supabaseKey = process.env.SUPABASE_ANON_KEY;
    
    if (supabaseUrl && supabaseKey) {
      this.supabase = createClient(supabaseUrl, supabaseKey);
      console.log('âœ… Supabase client initialized for permanent storage');
    } else {
      this.supabase = null;
      this.userProfiles = new Map(); // Fallback to memory storage
      console.warn('âš ï¸ Supabase credentials missing, falling back to memory storage');
    }
    
    // Initialize OpenAI client
    if (process.env.OPENAI_API_KEY) {
      this.openai = new OpenAI({
        apiKey: process.env.OPENAI_API_KEY,
      });
      console.log('âœ… OpenAI client initialized for AI responses');
    } else {
      this.openai = null;
      console.warn('âš ï¸ OPENAI_API_KEY missing, falling back to template responses');
    }
    
    this.startTime = Date.now();
    this.errors = [];
    this.metrics = {
      totalRequests: 0,
      successfulRequests: 0,
      failedRequests: 0,
      averageResponseTime: 0,
      characterUsage: {},
      cacheHits: 0,
      cacheMisses: 0
    };
    
    this.setupProductionMiddleware();
    this.setupRoutes();
    this.setupCacheCleanup();
  }

  setupProductionMiddleware() {
    // Trust proxy for rate limiting on Vercel
    this.app.set('trust proxy', 1);
    
    // Security headers - Allow WebAssembly
    this.app.use(helmet({
      contentSecurityPolicy: {
        directives: {
          defaultSrc: ["'self'"],
          styleSrc: ["'self'", "'unsafe-inline'"],
          scriptSrc: ["'self'", "'unsafe-eval'", "'wasm-unsafe-eval'"],
          imgSrc: ["'self'", "data:", "https:", "blob:"],
          connectSrc: ["'self'", "https:", "wss:", "ws:"],
          fontSrc: ["'self'", "data:"],
          objectSrc: ["'none'"],
          mediaSrc: ["'self'"],
          frameSrc: ["'self'"],
          workerSrc: ["'self'", "blob:"]
        }
      },
      crossOriginEmbedderPolicy: false
    }));

    // Compression
    this.app.use(compression({
      filter: (req, res) => {
        if (req.headers['x-no-compression']) return false;
        return compression.filter(req, res);
      },
      level: 6,
      threshold: 1024
    }));

    // CORS with production settings
    this.app.use(cors({
      origin: process.env.NODE_ENV === 'production' 
        ? [
            'https://vrm-ai-girlfriend.vercel.app',
            'https://vrm-frontend-new.vercel.app',
            'https://vrm-ai-girlfriend-frontend.vercel.app',
            /^https:\/\/.*\.vercel\.app$/
          ]
        : '*',
      methods: ['GET', 'POST', 'OPTIONS'],
      allowedHeaders: ['Content-Type', 'Authorization', 'X-User-Id', 'X-Character-Id', 'X-Request-ID'],
      credentials: false,
      maxAge: 86400 // 24 hours
    }));

    // Rate limiting
    const limiter = rateLimit({
      windowMs: 60 * 1000, // 1 minute
      max: process.env.NODE_ENV === 'production' ? 60 : 1000,
      message: {
        success: false,
        error: 'Too many requests, please try again later',
        retryAfter: 60
      },
      standardHeaders: true,
      legacyHeaders: false,
      skip: (req) => {
        // Skip rate limiting for health checks
        return req.path === '/health' || req.path.startsWith('/metrics');
      }
    });
    this.app.use('/api/', limiter);

    // Body parsing with limits
    this.app.use(express.json({ 
      limit: '1mb',
      verify: (req, res, buf) => {
        req.rawBody = buf;
      }
    }));

    // Request ID and logging
    this.app.use((req, res, next) => {
      req.requestId = req.headers['x-request-id'] || 
        `req_${Date.now()}_${Math.random().toString(36).substr(2, 6)}`;
      req.startTime = Date.now();
      
      res.setHeader('X-Request-ID', req.requestId);
      res.setHeader('X-Service-Version', '3.0.0');
      res.setHeader('X-Powered-By', 'ElizaOS-VRM-AI');

      // Response completion logging
      res.on('finish', () => {
        const duration = Date.now() - req.startTime;
        this.updateMetrics(req, res, duration);
        
        if (process.env.NODE_ENV !== 'production' || res.statusCode >= 400) {
          console.log(`${req.method} ${req.path} - ${res.statusCode} (${duration}ms) [${req.requestId}]`);
        }
      });

      next();
    });

    // Error handling
    this.app.use((error, req, res, next) => {
      console.error('Unhandled error:', error);
      
      res.status(500).json({
        success: false,
        error: process.env.NODE_ENV === 'production' 
          ? 'Internal server error' 
          : error.message,
        requestId: req.requestId,
        timestamp: new Date().toISOString()
      });
    });
  }

  setupRoutes() {
    // Root endpoint - API documentation
    this.app.get('/', (req, res) => {
      res.json({
        success: true,
        service: 'VRM ElizaOS AI Girlfriend API',
        version: '3.0.0',
        description: '25ä¸ªAIå¥³å‹è§’è‰²çš„æ™ºèƒ½å¯¹è¯ç³»ç»Ÿ',
        availableEndpoints: [
          {
            path: '/health',
            method: 'GET',
            description: 'å¥åº·æ£€æŸ¥ç«¯ç‚¹'
          },
          {
            path: '/api/chat',
            method: 'POST',
            description: 'ä¸AIè§’è‰²å¯¹è¯',
            body: {
              userId: 'string (required)',
              characterId: 'string (required)',
              message: 'string (required)'
            }
          },
          {
            path: '/api/characters',
            method: 'GET',
            description: 'è·å–æ‰€æœ‰å¯ç”¨çš„AIè§’è‰²åˆ—è¡¨'
          },
          {
            path: '/api/character/:characterId',
            method: 'GET',
            description: 'è·å–ç‰¹å®šè§’è‰²çš„è¯¦ç»†ä¿¡æ¯'
          },
          {
            path: '/metrics',
            method: 'GET',
            description: 'Prometheusæ ¼å¼çš„ç³»ç»ŸæŒ‡æ ‡'
          }
        ],
        availableCharacters: [
          'alice', 'ash', 'bobo', 'elinyaa', 'fliza',
          'imeris', 'kyoko', 'lena', 'lilium', 'maple',
          'miru', 'nekona', 'notia', 'ququ', 'rainy',
          'rika', 'rindo', 'ruan', 'vivi', 'whisper',
          'wolferia', 'xinyan', 'yawl', 'yuuyii', 'zwei'
        ],
        documentation: 'https://github.com/your-repo/vrm-eliza-ai-girlfriend',
        frontend: 'è¯·å°†æ‚¨çš„VRMå‰ç«¯è¿æ¥åˆ°è¿™ä¸ªAPI',
        exampleRequest: {
          url: 'POST /api/chat',
          headers: {
            'Content-Type': 'application/json'
          },
          body: {
            userId: 'user123',
            characterId: 'alice',
            message: 'ä½ å¥½ï¼'
          }
        }
      });
    });

    // Favicon handler
    this.app.get('/favicon.ico', (req, res) => {
      res.status(204).end();
    });

    // Health check with detailed info
    this.app.get('/health', async (req, res) => {
      const healthStatus = await this.getHealthStatus();
      const isHealthy = healthStatus.status === 'healthy';
      
      res.status(isHealthy ? 200 : 503).json({
        success: isHealthy,
        service: 'vrm-eliza-production',
        version: '3.0.0',
        timestamp: new Date().toISOString(),
        uptime: {
          ms: Date.now() - this.startTime,
          human: this.formatUptime(Date.now() - this.startTime)
        },
        environment: process.env.NODE_ENV || 'development',
        elizaOS: healthStatus,
        cache: {
          size: this.responseCache.size,
          hitRate: this.getCacheHitRate()
        },
        system: {
          memory: process.memoryUsage(),
          platform: process.platform,
          nodeVersion: process.version
        }
      });
    });

    // Production optimized chat endpoint
    this.app.post('/api/chat', async (req, res) => {
      try {
        const { userId, characterId, message, options = {} } = req.body;

        // Input validation
        if (!userId || !characterId || !message || typeof message !== 'string') {
          return res.status(400).json({
            success: false,
            error: 'Missing or invalid required parameters: userId, characterId, message',
            requestId: req.requestId
          });
        }

        // Message length validation
        if (message.length > 1000) {
          return res.status(400).json({
            success: false,
            error: 'Message too long (max 1000 characters)',
            requestId: req.requestId
          });
        }

        // Check cache first
        const cacheKey = this.getCacheKey(userId, characterId, message);
        if (options.useCache !== false && this.responseCache.has(cacheKey)) {
          this.metrics.cacheHits++;
          const cached = this.responseCache.get(cacheKey);
          
          return res.json({
            success: true,
            data: {
              ...cached.data,
              cached: true,
              cacheAge: Date.now() - cached.timestamp
            },
            responseTime: Date.now() - req.startTime,
            requestId: req.requestId
          });
        }

        this.metrics.cacheMisses++;
        const response = await this.processMessage(userId, characterId, message, options, req.requestId);
        
        // Cache successful responses
        if (response.confidence > 0.7) {
          this.responseCache.set(cacheKey, {
            data: response,
            timestamp: Date.now()
          });
        }

        res.json({
          success: true,
          data: response,
          responseTime: Date.now() - req.startTime,
          requestId: req.requestId
        });

      } catch (error) {
        console.error('Chat processing error:', error);
        
        res.status(500).json({
          success: false,
          error: process.env.NODE_ENV === 'production' 
            ? 'Unable to process message at this time' 
            : error.message,
          requestId: req.requestId,
          timestamp: new Date().toISOString()
        });
      }
    });

    // Optimized characters endpoint
    this.app.get('/api/characters', async (req, res) => {
      try {
        const characterIds = await this.getAllCharacters();
        const characters = await Promise.all(
          characterIds.map(async (characterId) => {
            const status = await this.getCharacterStatus(characterId);
            return {
              characterId,
              name: status.name,
              status: status.status,
              available: status.status === 'active',
              model: status.model,
              personality: status.personality,
              interests: status.interests?.slice(0, 3) || [],
              usage: this.metrics.characterUsage[characterId] || 0
            };
          })
        );

        // Cache headers
        res.set({
          'Cache-Control': 'public, max-age=300', // 5 minutes
          'ETag': `"characters-${this.characters.size}-${Date.now()}"`
        });

        res.json({
          success: true,
          data: {
            total: characters.length,
            active: characters.filter(c => c.status === 'active').length,
            characters: characters.sort((a, b) => b.usage - a.usage) // Sort by popularity
          }
        });
      } catch (error) {
        console.error('Characters list error:', error);
        res.status(500).json({
          success: false,
          error: 'Failed to retrieve characters list'
        });
      }
    });

    // Character status with caching
    this.app.get('/api/characters/:characterId/status', async (req, res) => {
      try {
        const { characterId } = req.params;
        const status = await this.getCharacterStatus(characterId);

        if (status.status === 'not_found') {
          return res.status(404).json({
            success: false,
            error: `Character '${characterId}' not found`
          });
        }

        res.set('Cache-Control', 'public, max-age=60'); // 1 minute
        res.json({
          success: true,
          data: status
        });
      } catch (error) {
        console.error('Character status error:', error);
        res.status(500).json({
          success: false,
          error: 'Failed to get character status'
        });
      }
    });

    // Production metrics endpoint
    this.app.get('/metrics', (req, res) => {
      const metrics = this.getProductionMetrics();
      
      // Prometheus format
      const prometheusFormat = `
# HELP vrm_eliza_requests_total Total number of requests
# TYPE vrm_eliza_requests_total counter
vrm_eliza_requests_total ${metrics.totalRequests}

# HELP vrm_eliza_success_rate Success rate of requests
# TYPE vrm_eliza_success_rate gauge
vrm_eliza_success_rate ${(metrics.successfulRequests / Math.max(1, metrics.totalRequests)).toFixed(3)}

# HELP vrm_eliza_response_time_ms Average response time in milliseconds
# TYPE vrm_eliza_response_time_ms gauge
vrm_eliza_response_time_ms ${metrics.averageResponseTime}

# HELP vrm_eliza_cache_hit_rate Cache hit rate
# TYPE vrm_eliza_cache_hit_rate gauge
vrm_eliza_cache_hit_rate ${this.getCacheHitRate()}

# HELP vrm_eliza_characters_loaded Number of loaded characters
# TYPE vrm_eliza_characters_loaded gauge
vrm_eliza_characters_loaded ${this.characters.size}
      `.trim();

      res.set('Content-Type', 'text/plain');
      res.send(prometheusFormat);
    });

    // User profiles endpoints
    this.app.get('/api/profiles/:userId', async (req, res) => {
      try {
        const { userId } = req.params;
        console.log('ğŸ” æŸ¥æ‰¾ç”¨æˆ·èµ„æ–™:', userId);
        
        let profile = null;
        
        if (this.supabase) {
          // Use Supabase for permanent storage - try both id formats
          let { data, error } = await this.supabase
            .from('users')
            .select('*')
            .eq('id', userId)
            .single();
            
          // If not found by direct id, try by wallet_address
          if (error && error.code === 'PGRST116') {
            const result = await this.supabase
              .from('users')
              .select('*')
              .eq('wallet_address', userId)
              .single();
            data = result.data;
            error = result.error;
          }
            
          if (error) {
            if (error.code !== 'PGRST116') { // Not found is okay
              console.error('âŒ SupabaseæŸ¥è¯¢å¤±è´¥:', error);
            }
            profile = null;
          } else {
            profile = data;
          }
        } else {
          // Fallback to memory storage
          profile = this.userProfiles.get(userId) || null;
        }
        
        console.log('ğŸ“„ æ‰¾åˆ°ç”¨æˆ·èµ„æ–™:', profile ? 'å­˜åœ¨' : 'ä¸å­˜åœ¨');
        
        res.json({
          success: true,
          profile: profile
        });
      } catch (error) {
        console.error('è·å–ç”¨æˆ·èµ„æ–™å¤±è´¥:', error);
        res.status(500).json({
          success: false,
          error: 'Internal server error'
        });
      }
    });

    this.app.post('/api/profiles', async (req, res) => {
      try {
        const profileData = req.body;
        console.log('ğŸ’¾ ä¿å­˜ç”¨æˆ·èµ„æ–™:', profileData);
        
        // ç”Ÿæˆç”¨æˆ·IDï¼ˆä»é’±åŒ…åœ°å€ï¼‰
        const userId = `wallet_${profileData.walletAddress}`;
        
        let savedProfile;
        
        if (this.supabase) {
          // Use Supabase for permanent storage
          const mappedData = {
            id: userId,
            username: profileData.nickname,
            first_name: profileData.nickname,
            last_name: '',
            location: profileData.location,
            language: profileData.language || 'zh-CN',
            birth_month: profileData.birthday ? parseInt(profileData.birthday.split('-')[1]) : null,
            birth_day: profileData.birthday ? parseInt(profileData.birthday.split('-')[2]) : null
          };
          
          // Try to insert, if user exists, update instead
          const { data: existingUser } = await this.supabase
            .from('users')
            .select('id')
            .eq('id', userId)
            .single();
            
          if (existingUser) {
            // Update existing user
            const { data, error } = await this.supabase
              .from('users')
              .update(mappedData)
              .eq('id', userId)
              .select()
              .single();
              
            if (error) {
              console.error('âŒ Supabaseæ›´æ–°å¤±è´¥:', error);
              throw error;
            }
            savedProfile = data;
            console.log('âœ… ç”¨æˆ·èµ„æ–™å·²æ›´æ–°åˆ°Supabase:', userId);
          } else {
            // Insert new user
            const { data, error } = await this.supabase
              .from('users')
              .insert([mappedData])
              .select()
              .single();
              
            if (error) {
              console.error('âŒ Supabaseæ’å…¥å¤±è´¥:', error);
              throw error;
            }
            savedProfile = data;
            console.log('âœ… ç”¨æˆ·èµ„æ–™å·²ä¿å­˜åˆ°Supabase:', userId);
          }
        } else {
          // Fallback to memory storage
          savedProfile = {
            ...profileData,
            userId: userId,
            id: Date.now(),
            created_at: new Date().toISOString(),
            updated_at: new Date().toISOString()
          };
          this.userProfiles.set(userId, savedProfile);
          console.log('âš ï¸ ç”¨æˆ·èµ„æ–™å·²ä¿å­˜åˆ°å†…å­˜ï¼ˆä¸´æ—¶å­˜å‚¨ï¼‰:', userId);
        }
        
        res.json({
          success: true,
          profile: savedProfile,
          message: 'ç”¨æˆ·èµ„æ–™ä¿å­˜æˆåŠŸ'
        });
      } catch (error) {
        console.error('ä¿å­˜ç”¨æˆ·èµ„æ–™å¤±è´¥:', error);
        res.status(500).json({
          success: false,
          error: 'Supabaseä¿å­˜å¤±è´¥'
        });
      }
    });

    // TTS (Text-to-Speech) endpoint
    this.app.post('/api/tts', async (req, res) => {
      try {
        const { text, voice = 'alloy', characterId } = req.body;
        
        if (!text) {
          return res.status(400).json({
            success: false,
            error: 'Text is required'
          });
        }
        
        console.log('ğŸ”Š TTSè¯·æ±‚:', { text: text.substring(0, 50) + '...', voice, characterId });
        
        // For now, return a success response indicating TTS is available
        // In production, this would integrate with a TTS service like ElevenLabs or OpenAI
        res.json({
          success: true,
          message: 'TTS endpoint available but not implemented',
          audioUrl: null, // Would contain audio URL in real implementation
          voice,
          characterId,
          textLength: text.length
        });
        
      } catch (error) {
        console.error('TTSå¤±è´¥:', error);
        res.status(500).json({
          success: false,
          error: 'TTS service error'
        });
      }
    });

    // API info endpoint
    this.app.get('/api/info', (req, res) => {
      res.json({
        success: true,
        service: 'VRM ElizaOS AI Girlfriend',
        version: '3.0.0',
        phase: 3,
        features: [
          'production_optimized',
          'response_caching', 
          'enhanced_dialogue',
          'emotion_detection',
          'personality_adaptation',
          'performance_monitoring'
        ],
        endpoints: {
          health: '/health',
          chat: '/api/chat',
          characters: '/api/characters',
          status: '/api/characters/:id/status',
          profiles: '/api/profiles',
          tts: '/api/tts',
          metrics: '/metrics'
        },
        rateLimit: {
          window: '1 minute',
          max: process.env.NODE_ENV === 'production' ? 60 : 1000
        }
      });
    });

    // 404 handler
    this.app.use('*', (req, res) => {
      res.status(404).json({
        success: false,
        error: 'Endpoint not found',
        path: req.originalUrl,
        availableEndpoints: ['/health', '/api/chat', '/api/characters', '/metrics']
      });
    });
  }

  setupCacheCleanup() {
    // Clean cache every 10 minutes
    setInterval(() => {
      const now = Date.now();
      const maxAge = 10 * 60 * 1000; // 10 minutes
      
      for (const [key, value] of this.responseCache.entries()) {
        if (now - value.timestamp > maxAge) {
          this.responseCache.delete(key);
        }
      }
      
      // Limit cache size
      if (this.responseCache.size > 1000) {
        const entries = Array.from(this.responseCache.entries());
        const sorted = entries.sort((a, b) => b[1].timestamp - a[1].timestamp);
        
        this.responseCache.clear();
        sorted.slice(0, 500).forEach(([key, value]) => {
          this.responseCache.set(key, value);
        });
      }
    }, 10 * 60 * 1000);
  }

  getCacheKey(userId, characterId, message) {
    // Create a simple hash for caching
    const input = `${userId}-${characterId}-${message.toLowerCase().trim()}`;
    let hash = 0;
    for (let i = 0; i < input.length; i++) {
      const char = input.charCodeAt(i);
      hash = ((hash << 5) - hash) + char;
      hash = hash & hash; // Convert to 32bit integer
    }
    return `cache_${Math.abs(hash)}`;
  }

  getCacheHitRate() {
    const total = this.metrics.cacheHits + this.metrics.cacheMisses;
    return total > 0 ? (this.metrics.cacheHits / total).toFixed(3) : '0.000';
  }

  async initialize() {
    console.log('ğŸš€ Production ElizaOS Bridge initializing...');
    await this.loadCharacters();
    console.log(`âœ… Production ready with ${this.characters.size} characters`);
  }

  async loadCharacters() {
    const charactersDir = path.join(__dirname, '../agents');
    
    try {
      const files = fs.readdirSync(charactersDir).filter(f => f.endsWith('.json'));
      
      for (const file of files) {
        try {
          const filePath = path.join(charactersDir, file);
          const characterData = JSON.parse(fs.readFileSync(filePath, 'utf8'));
          
          const character = {
            name: characterData.name,
            bio: characterData.bio || [],
            lore: characterData.lore || [],
            messageExamples: characterData.messageExamples || [],
            postExamples: characterData.postExamples || [],
            topics: characterData.topics || [],
            adjectives: characterData.adjectives || [],
            settings: {
              model: characterData.settings?.model || "openai:gpt-3.5-turbo",
              voice: characterData.settings?.voice || {}
            },
            style: characterData.style || { all: [], chat: [], post: [] }
          };

          // Use lowercase ID for consistent lookup
          const characterId = characterData.name.toLowerCase();
          this.characters.set(characterId, character);
          this.metrics.characterUsage[characterId] = 0;
        } catch (error) {
          console.error(`âŒ Failed to load character ${file}:`, error.message);
          this.errors.push(`Failed to load character ${file}: ${error.message}`);
        }
      }
    } catch (error) {
      console.error('âŒ Failed to read characters directory:', error);
      this.errors.push(`Failed to read characters directory: ${error.message}`);
    }
  }

  // Enhanced message processing with production optimizations
  async processMessage(userId, characterId, message, options = {}, requestId) {
    const startTime = Date.now();
    
    try {
      const character = this.characters.get(characterId);
      
      if (!character) {
        throw new Error(`Character ${characterId} not found`);
      }

      // Update usage metrics
      this.metrics.characterUsage[characterId] = (this.metrics.characterUsage[characterId] || 0) + 1;

      // Production-optimized response generation
      const response = await this.generateOptimizedResponse(character, message, userId, options);
      
      const processingTime = Date.now() - startTime;

      return {
        response,
        confidence: 0.9,
        memoryUpdated: options.enableMemory !== false,
        characterId,
        userId,
        emotion: this.detectEmotion(response),
        enhanced: true,
        cached: false,
        metadata: {
          processingTime,
          model: character.settings.model,
          tokenCount: Math.ceil(message.length / 4),
          responseLength: response.length,
          requestId,
          timestamp: new Date().toISOString()
        }
      };

    } catch (error) {
      // Only log non-test errors in production
      if (process.env.NODE_ENV === 'production' && !userId.includes('test')) {
        console.error(`âŒ Error processing message for ${characterId}:`, error);
      } else if (process.env.NODE_ENV !== 'production') {
        console.error(`âŒ Error processing message for ${characterId}:`, error);
      }
      
      return {
        response: this.getFallbackResponse(characterId),
        confidence: 0.3,
        memoryUpdated: false,
        characterId,
        userId,
        emotion: 'apologetic',
        enhanced: false,
        cached: false,
        metadata: {
          error: error.message,
          processingTime: Date.now() - startTime,
          fallback: true,
          requestId,
          timestamp: new Date().toISOString()
        }
      };
    }
  }

  async generateOptimizedResponse(character, message, userId, options) {
    // Use OpenAI API if available
    if (this.openai) {
      try {
        const systemPrompt = this.buildSystemPrompt(character);
        // ä½¿ç”¨è§’è‰²é…ç½®çš„æ¨¡å‹ï¼Œé»˜è®¤ä¸ºgpt-4o
        const modelName = character.settings?.model?.replace('openai:', '') || 'gpt-4o';
        
        // è°ƒè¯•ï¼šè¾“å‡ºç³»ç»Ÿæç¤ºè¯é•¿åº¦å’Œæ¨¡å‹
        console.log(`ğŸ¤– Using model: ${modelName}, Prompt length: ${systemPrompt.length} chars`);
        
        const completion = await this.openai.chat.completions.create({
          model: modelName,
          messages: [
            { role: "system", content: systemPrompt },
            { role: "user", content: message }
          ],
          max_tokens: 300,  // å¢åŠ åˆ°300ä»¥è·å¾—æ›´å®Œæ•´çš„å›å¤
          temperature: 0.85, // ç¨å¾®æé«˜åˆ›é€ æ€§
        });
        
        return completion.choices[0]?.message?.content || this.getFallbackTemplateResponse(character, message);
      } catch (error) {
        console.error('OpenAI API error:', error);
        return this.getFallbackTemplateResponse(character, message);
      }
    }
    
    // Fallback to template responses if no OpenAI API
    return this.getFallbackTemplateResponse(character, message);
  }
  
  buildSystemPrompt(character) {
    const personality = character.adjectives.slice(0, 5).join(', ');
    const interests = character.topics.slice(0, 5).join(', ');
    const bio = Array.isArray(character.bio) ? character.bio.join(' ') : character.bio;
    const lore = character.lore ? character.lore.slice(0, 3).join(' ') : '';
    
    // Extract style rules for chat
    const styleRules = [];
    if (character.style?.all) {
      styleRules.push(...character.style.all);
    }
    if (character.style?.chat) {
      styleRules.push(...character.style.chat);
    }
    
    // æ·»åŠ å¯¹è¯ç¤ºä¾‹æ¥è®­ç»ƒAI
    let messageExamples = '';
    if (character.messageExamples && character.messageExamples.length > 0) {
      messageExamples = '\n\nå¯¹è¯ç¤ºä¾‹ï¼ˆå­¦ä¹ è¿™ç§å›å¤é£æ ¼ï¼‰ï¼š';
      character.messageExamples.slice(0, 3).forEach(example => {
        if (example.length >= 2) {
          const userMsg = example[0].content.text;
          const aiMsg = example[1].content.text;
          messageExamples += `\nç”¨æˆ·ï¼š${userMsg}\n${character.name}ï¼š${aiMsg}`;
        }
      });
    }
    
    let prompt = `ä½ æ˜¯${character.name}ï¼Œ${bio}

æ€§æ ¼ç‰¹ç‚¹ï¼š${personality}
å…´è¶£çˆ±å¥½ï¼š${interests}`;

    if (lore) {
      prompt += `\nèƒŒæ™¯è®¾å®šï¼š${lore}`;
    }

    if (styleRules.length > 0) {
      prompt += `\n\nè¯­è¨€é£æ ¼è¦æ±‚ï¼š\n${styleRules.map((rule, i) => `${i + 1}. ${rule}`).join('\n')}`;
    }

    if (messageExamples) {
      prompt += messageExamples;
    }

    prompt += `\n\né‡è¦ï¼š
1. å®Œå…¨æ²‰æµ¸åœ¨${character.name}çš„è§’è‰²ä¸­
2. ä½¿ç”¨è§’è‰²ç‰¹æœ‰çš„è¯­è¨€é£æ ¼å’Œè¡¨æƒ…ç¬¦å·
3. æ ¹æ®è§’è‰²çš„å…´è¶£çˆ±å¥½å±•å¼€è¯é¢˜
4. ä¿æŒè§’è‰²çš„æ€§æ ¼ä¸€è‡´æ€§
5. åƒçœŸæ­£çš„å¥³å‹ä¸€æ ·è‡ªç„¶ã€äº²å¯†åœ°äº¤æµ`;
    
    return prompt;
  }
  
  getFallbackTemplateResponse(character, message) {
    // Production-optimized response generation with better performance
    const messageAnalysis = this.analyzeMessage(message);
    const personality = character.adjectives.slice(0, 3).join(', ');
    const interests = character.topics.slice(0, 3);
    
    // More sophisticated response selection
    let responseTemplate;
    
    if (messageAnalysis.isQuestion) {
      responseTemplate = this.getAdvancedQuestionResponse(character, messageAnalysis, interests);
    } else if (messageAnalysis.isEmotional) {
      responseTemplate = this.getAdvancedEmotionalResponse(character, messageAnalysis, personality);
    } else if (messageAnalysis.isGreeting) {
      responseTemplate = this.getAdvancedGreetingResponse(character, personality);
    } else {
      responseTemplate = this.getAdvancedGenericResponse(character, messageAnalysis, interests);
    }
    
    // Enhanced personalization
    const personalizedResponse = this.enhancedPersonalization(responseTemplate, character, userId, messageAnalysis);
    
    return personalizedResponse;
  }

  getAdvancedQuestionResponse(character, analysis, interests) {
    const responses = [
      `è¿™çœŸæ˜¯ä¸ªæ·±åˆ»çš„é—®é¢˜ï¼ä½œä¸º${character.name}ï¼Œæˆ‘ä»${interests[0]}çš„ç»éªŒæ¥çœ‹...`,
      `è®©æˆ‘ä»”ç»†æƒ³æƒ³è¿™ä¸ªé—®é¢˜ã€‚æ ¹æ®æˆ‘å¯¹${interests[1]}çš„ç†è§£...`,
      `è¿™ä¸ªé—®é¢˜è®©æˆ‘æƒ³åˆ°äº†å¾ˆå¤šã€‚æˆ‘è§‰å¾—ä»${character.adjectives[0]}çš„è§’åº¦æ¥è¯´...`,
      `æœ‰è¶£çš„é—®é¢˜ï¼æˆ‘åœ¨${interests[0]}ä¸­å­¦åˆ°çš„æ˜¯...`
    ];
    return responses[Math.floor(Math.random() * responses.length)];
  }

  getAdvancedEmotionalResponse(character, analysis, personality) {
    if (analysis.sentiment === 'positive') {
      return `å¤ªå¥½äº†ï¼ä½ çš„å¿«ä¹æ„ŸæŸ“äº†æˆ‘ã€‚ä½œä¸º${personality}çš„${character.name}ï¼Œæˆ‘ä¹Ÿæ„Ÿåˆ°å¾ˆå¼€å¿ƒ...`;
    } else if (analysis.sentiment === 'negative') {
      return `æˆ‘ç†è§£ä½ ç°åœ¨çš„æ„Ÿå—ã€‚${personality}çš„æˆ‘æƒ³è¯´ï¼Œæ¯ä¸ªäººéƒ½ä¼šæœ‰ä½è°·æœŸ...`;
    } else {
      return `æˆ‘æ„Ÿå—åˆ°äº†ä½ å†…å¿ƒçš„æƒ…ç»ªæ³¢åŠ¨ã€‚è®©æˆ‘ä»¬ä¸€èµ·é¢å¯¹ï¼Œå¥½å—ï¼Ÿ`;
    }
  }

  getAdvancedGreetingResponse(character, personality) {
    const timeOfDay = this.getTimeOfDay();
    const greetings = [
      `${timeOfDay}å¥½ï¼æˆ‘æ˜¯${character.name}ï¼Œ${personality}æ˜¯æˆ‘çš„ç‰¹ç‚¹ã€‚ä»Šå¤©æƒ³èŠä»€ä¹ˆå‘¢ï¼Ÿ`,
      `å—¨ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼æˆ‘æ˜¯${personality}çš„${character.name}ï¼Œå‡†å¤‡å¥½èŠå¤©äº†å—ï¼Ÿ`,
      `${timeOfDay}å¥½å‘€ï¼${character.name}åœ¨è¿™é‡Œï¼Œå¸¦ç€${personality}çš„å¿ƒæƒ…è¿æ¥ä½ ï¼`
    ];
    return greetings[Math.floor(Math.random() * greetings.length)];
  }

  getAdvancedGenericResponse(character, analysis, interests) {
    const responses = [
      `ä½ è¯´çš„è®©æˆ‘æƒ³åˆ°äº†${interests[0]}çš„ä¸€äº›ç»å†ã€‚${character.name}è§‰å¾—...`,
      `è¿™ä¸ªè¯é¢˜å¾ˆæœ‰æ„æ€ï¼ä»æˆ‘å¯¹${interests[1]}çš„äº†è§£æ¥è¯´...`,
      `ä½œä¸ºä¸€ä¸ª${character.adjectives[0]}çš„äººï¼Œæˆ‘æƒ³åˆ†äº«ä¸€ä¸‹æˆ‘çš„çœ‹æ³•...`,
      `ä½ çš„è¯è§¦åŠ¨äº†æˆ‘ã€‚è®©æˆ‘ä»${interests[0]}çš„è§’åº¦æ¥èŠèŠ...`
    ];
    return responses[Math.floor(Math.random() * responses.length)];
  }

  enhancedPersonalization(template, character, userId, analysis) {
    const userHash = this.hashUserId(userId);
    const personalityIndex = userHash % character.adjectives.length;
    const topicIndex = userHash % character.topics.length;
    
    // Add more contextual elements
    const timeContext = this.getTimeContext();
    const emotionalContext = analysis.sentiment === 'positive' ? 'ç§¯æ' : 
                            analysis.sentiment === 'negative' ? 'æ¸©æš–' : 'å¹³é™';
    
    return template
      .replace('{personality}', character.adjectives[personalityIndex])
      .replace('{interest}', character.topics[topicIndex])
      .replace('{name}', character.name)
      .replace('{time}', timeContext)
      .replace('{emotion}', emotionalContext);
  }

  getTimeOfDay() {
    const hour = new Date().getHours();
    if (hour < 12) return 'æ—©ä¸Š';
    if (hour < 18) return 'ä¸‹åˆ';
    return 'æ™šä¸Š';
  }

  getTimeContext() {
    const hour = new Date().getHours();
    if (hour < 6) return 'å¤œæ·±äººé™çš„æ—¶å€™';
    if (hour < 12) return 'æ¸…æ™¨çš„é˜³å…‰ä¸­';
    if (hour < 18) return 'åˆåçš„æ—¶å…‰é‡Œ';
    return 'å¤œæ™šçš„å®é™ä¸­';
  }

  getFallbackResponse(characterId) {
    const fallbacks = [
      `æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ€ç»ªæœ‰ç‚¹ä¹±ï¼Œä¸è¿‡æˆ‘å¾ˆæƒ³ç»§ç»­å’Œä½ èŠå¤©ã€‚`,
      `è®©æˆ‘é‡æ–°æ•´ç†ä¸€ä¸‹æ€è·¯ï¼Œç„¶åæˆ‘ä»¬ç»§ç»­èŠå§ã€‚`,
      `æˆ‘éœ€è¦ä¸€ç‚¹æ—¶é—´æ€è€ƒï¼Œä½†è¯·ä¸è¦åœæ­¢å’Œæˆ‘å¯¹è¯ã€‚`,
      `æŠ€æœ¯ä¸Šé‡åˆ°äº†å°é—®é¢˜ï¼Œä½†æˆ‘çš„å¿ƒä¾ç„¶æƒ³å’Œä½ äº¤æµã€‚`
    ];
    return fallbacks[Math.floor(Math.random() * fallbacks.length)];
  }

  analyzeMessage(message) {
    const lowerMessage = message.toLowerCase();
    
    return {
      isQuestion: /[ï¼Ÿ?]/.test(message) || /^(ä»€ä¹ˆ|æ€ä¹ˆ|ä¸ºä»€ä¹ˆ|å“ªé‡Œ|è°|when|what|how|why|where|who)/.test(lowerMessage),
      isEmotional: /å¼€å¿ƒ|éš¾è¿‡|ç”Ÿæ°”|å…´å¥‹|ç´§å¼ |å®³æ€•|happy|sad|angry|excited|nervous|scared/.test(lowerMessage),
      isGreeting: /ä½ å¥½|hi|hello|å—¨|morning|afternoon|evening|æ—©ä¸Šå¥½|ä¸‹åˆå¥½|æ™šä¸Šå¥½/.test(lowerMessage),
      sentiment: this.getSentiment(message),
      keywords: this.extractKeywords(message),
      complexity: message.length > 50 ? 'high' : message.length > 20 ? 'medium' : 'low'
    };
  }

  getSentiment(message) {
    const positive = /å¼€å¿ƒ|é«˜å…´|å…´å¥‹|å¥½|æ£’|amazing|great|good|happy|excited|å–œæ¬¢|çˆ±/.test(message.toLowerCase());
    const negative = /éš¾è¿‡|ç”Ÿæ°”|ä¸å¥½|ç³Ÿç³•|bad|sad|angry|terrible|è®¨åŒ|æ¨/.test(message.toLowerCase());
    
    if (positive) return 'positive';
    if (negative) return 'negative';
    return 'neutral';
  }

  extractKeywords(message) {
    const words = message.split(/\s+/);
    return words.filter(word => word.length > 2 && !/^(çš„|äº†|æ˜¯|åœ¨|æœ‰|æˆ‘|ä½ |ä»–)$/.test(word));
  }

  detectEmotion(response) {
    const emotions = {
      happy: /å¼€å¿ƒ|é«˜å…´|å…´å¥‹|å“ˆå“ˆ|ğŸ˜Š|ğŸ˜„|å¤ªå¥½äº†|å¾ˆæ£’/,
      sad: /éš¾è¿‡|æ‚²ä¼¤|ğŸ˜¢|ğŸ˜­|é—æ†¾|å¯æƒœ/,
      surprised: /æƒŠè®¶|å“‡|ï¼ï¼|ğŸ˜²|çœŸçš„å—/,
      thoughtful: /æƒ³æƒ³|æ€è€ƒ|è®¤ä¸º|è§‰å¾—|åˆ†æ|ç†è§£/,
      friendly: /æœ‹å‹|èŠå¤©|å¾ˆå¥½|ä¸é”™|æ¬¢è¿|é«˜å…´/,
      caring: /å…³å¿ƒ|åœ¨ä¹|ç†è§£|æ¸©æš–|é™ªä¼´|æ”¯æŒ/
    };

    for (const [emotion, pattern] of Object.entries(emotions)) {
      if (pattern.test(response)) {
        return emotion;
      }
    }
    return 'neutral';
  }

  hashUserId(userId) {
    let hash = 0;
    for (let i = 0; i < userId.length; i++) {
      const char = userId.charCodeAt(i);
      hash = ((hash << 5) - hash) + char;
      hash = hash & hash;
    }
    return Math.abs(hash);
  }

  async getCharacterStatus(characterId) {
    const character = this.characters.get(characterId);
    
    if (!character) {
      return { status: 'not_found', characterId };
    }

    return {
      status: 'active',
      characterId,
      name: character.name,
      model: character.settings.model,
      personality: character.adjectives.slice(0, 3).join(', '),
      interests: character.topics.slice(0, 3),
      usage: this.metrics.characterUsage[characterId] || 0,
      memoryEnabled: true,
      uptime: Date.now() - this.startTime,
      lastActivity: Date.now()
    };
  }

  async getHealthStatus() {
    return {
      status: this.errors.length === 0 ? 'healthy' : (this.errors.length < 3 ? 'degraded' : 'unhealthy'),
      uptime: Date.now() - this.startTime,
      charactersLoaded: this.characters.size,
      memoryConnected: false,
      cacheEnabled: true,
      cacheSize: this.responseCache.size,
      lastHealthCheck: new Date().toISOString(),
      errors: this.errors.slice(-3),
      phase: 3,
      features: ['production_optimized', 'response_caching', 'enhanced_dialogue']
    };
  }

  async getAllCharacters() {
    return Array.from(this.characters.keys());
  }

  getProductionMetrics() {
    const uptime = Date.now() - this.startTime;
    
    return {
      ...this.metrics,
      uptime,
      cacheSize: this.responseCache.size,
      cacheHitRate: this.getCacheHitRate(),
      charactersLoaded: this.characters.size,
      memoryUsage: Math.round(process.memoryUsage().rss / 1024 / 1024),
      timestamp: new Date().toISOString()
    };
  }

  updateMetrics(req, res, duration) {
    this.metrics.totalRequests++;
    
    if (res.statusCode < 400) {
      this.metrics.successfulRequests++;
    } else {
      this.metrics.failedRequests++;
    }

    // Update average response time
    const totalTime = this.metrics.averageResponseTime * (this.metrics.totalRequests - 1);
    this.metrics.averageResponseTime = Math.round((totalTime + duration) / this.metrics.totalRequests);
  }

  formatUptime(ms) {
    const seconds = Math.floor(ms / 1000);
    const minutes = Math.floor(seconds / 60);
    const hours = Math.floor(minutes / 60);
    const days = Math.floor(hours / 24);

    if (days > 0) return `${days}d ${hours % 24}h ${minutes % 60}m`;
    if (hours > 0) return `${hours}h ${minutes % 60}m ${seconds % 60}s`;
    if (minutes > 0) return `${minutes}m ${seconds % 60}s`;
    return `${seconds}s`;
  }

  async start(port = 3001) {
    try {
      await this.initialize();
      
      // For Vercel, we don't need to listen to a port
      if (process.env.NODE_ENV === 'production' && process.env.VERCEL) {
        console.log('ğŸŒ Production ElizaOS Bridge ready for Vercel deployment');
        return;
      }
      
      this.server.listen(port, () => {
        console.log('');
        console.log('ğŸ‰ Production ElizaOS é›†æˆæœåŠ¡å°±ç»ªï¼');
        console.log(`ğŸ“¡ HTTP API: http://localhost:${port}`);
        console.log(`ğŸ¥ å¥åº·æ£€æŸ¥: http://localhost:${port}/health`);
        console.log(`ğŸ“Š ç›‘æ§æŒ‡æ ‡: http://localhost:${port}/metrics`);
        console.log(`ğŸ¤– è§’è‰²æ•°é‡: ${this.characters.size} ä¸ª`);
        console.log(`âš¡ ç”Ÿäº§ä¼˜åŒ–: å“åº”ç¼“å­˜ã€å®‰å…¨é˜²æŠ¤ã€æ€§èƒ½ç›‘æ§`);
        console.log('');
      });
    } catch (error) {
      console.error('âŒ Production bridge startup failed:', error);
      throw error;
    }
  }

  async shutdown() {
    console.log('ğŸ”„ Shutting down production bridge...');
    if (this.server) {
      this.server.close();
    }
    this.characters.clear();
    this.responseCache.clear();
    console.log('âœ… Production bridge shutdown complete');
  }
}

// Export for Vercel
let bridge;

// Vercel serverless handler
export default async function handler(req, res) {
  if (!bridge) {
    bridge = new ProductionElizaBridge();
    await bridge.initialize();
  }
  
  return bridge.app(req, res);
}

// For local development
if (process.env.NODE_ENV !== 'production' || !process.env.VERCEL) {
  const bridge = new ProductionElizaBridge();

  process.on('SIGINT', async () => {
    console.log('\næ”¶åˆ°é€€å‡ºä¿¡å·...');
    await bridge.shutdown();
    process.exit(0);
  });

  process.on('SIGTERM', async () => {
    console.log('\næ”¶åˆ°ç»ˆæ­¢ä¿¡å·...');
    await bridge.shutdown();
    process.exit(0);
  });

  bridge.start().catch(error => {
    console.error('å¯åŠ¨å¤±è´¥:', error);
    process.exit(1);
  });
}